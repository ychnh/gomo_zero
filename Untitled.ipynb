{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def iter(fa)\n",
    "* fa\n",
    "1. mcst(fa) -> MCST, G\n",
    "    * F: call fa \n",
    "    * B: sample and create G = {(s,pi,z)}\n",
    "2. train(G) -> fb\n",
    "3. Eval fa vs fb\n",
    "    * Need Mfa(1) and Mfb()\n",
    "\n",
    "*  Now how to do this with multiple processes  \n",
    "* L2 reg c = 10**-4\n",
    "* anealling term EXT Data table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0015349388122559"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep(1)\n",
    "time()-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.038514852523804\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from time import time,sleep\n",
    "import torch\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "from ftemp import ftemp\n",
    "K = 3\n",
    "\n",
    "def infer(n):\n",
    "    # Construct data_loader, optimizer, etc.\n",
    "    #for b in trn_dataloader:\n",
    "        #print('h')\n",
    "        #x,pi,z = b\n",
    "        #x = x.float().cuda()\n",
    "        \n",
    "    model = ftemp(K).cuda()\n",
    "    for i in range(100):\n",
    "        x = torch.FloatTensor(180,3,3,3).cuda()\n",
    "        model(x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    A = time()\n",
    "    #num_processes = 20\n",
    "    num_processes = 1\n",
    "    model=None\n",
    "    # NOTE: this is required for the ``fork`` method to work\n",
    "    #model.share_memory()\n",
    "    processes = []\n",
    "    for rank in range(num_processes):\n",
    "        p = mp.Process(target=infer, args=(model,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    print(time()-A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 sep 24.793102264404297 6.1717212200164795 9.017511367797852\n",
    "#1 15.917717933654785, 6.459911584854126 9.816794872283936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 9]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ftemp; reload(ftemp)\n",
    "from ftemp import ftemp\n",
    "import torch\n",
    "f = ftemp(K=3)\n",
    "x = torch.FloatTensor(2,3,3,3)\n",
    "p,v = f(x)\n",
    "p.shape, v.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import mcst; reload(mcst)\n",
    "import util; reload(util)\n",
    "from mcst import Node, State,S\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "def backprop(z, T= 0, save_idx=[]):\n",
    "    G = []\n",
    "    \n",
    "    while(True):\n",
    "        a = S.node.up_a\n",
    "        S.undo(a)\n",
    "        \n",
    "        won = (z==S.node.p and z!=-1)\n",
    "        S.node.back(won, a)\n",
    "        \n",
    "        if S.i in save_idx: G.append([*S.get_xPI(),z])\n",
    "            \n",
    "        if(S.i == T): break\n",
    "            \n",
    "    return G\n",
    "\n",
    "def forward():\n",
    "    while(True):\n",
    "        a = S.node.branch()\n",
    "        S.do(a)\n",
    "        \n",
    "        over,z = S.isterminal()\n",
    "        if(over): break\n",
    "            \n",
    "    return z\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def ply(nsave=0):\n",
    "    T = S.i\n",
    "    z = forward()\n",
    "\n",
    "    B = S.i\n",
    "    save_idx = random.sample(range(T,B),nsave)\n",
    "    G = backprop(z, T, save_idx)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_gm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-35e75a48ea8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmcst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_gm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprgs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrn_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_gm' is not defined"
     ]
    }
   ],
   "source": [
    "mcst.model = f_gm(K=3).cuda()\n",
    "S = State(K=3)\n",
    "G = []\n",
    "for i in prgs( range(100) ): G+=ply(10)\n",
    "trn_dataloader = DataLoader(G, batch_size=64, shuffle=True)\n",
    "b = iter(trn_dataloader).next()\n",
    "#mcst.model()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing gen: 0\n",
      "[[0.11 0.1  0.1 ]\n",
      " [0.12 0.17 0.12]\n",
      " [0.12 0.   0.15]]\n",
      "[[0.13 0.15 0.04]\n",
      " [0.14 0.12 0.08]\n",
      " [0.09 0.15 0.1 ]]\n",
      "------------------\n",
      "E 0 B 0 loss: 74.69877624511719\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[0.   0.01 0.  ]\n",
      " [0.02 0.01 0.12]\n",
      " [0.   0.02 0.82]]\n",
      "------------------\n",
      "E 0 B 533 loss: 46.61298370361328\n",
      "[[0.  0.1 0. ]\n",
      " [0.  0.  0.1]\n",
      " [0.  0.8 0. ]]\n",
      "[[0.03 0.08 0.09]\n",
      " [0.   0.   0.14]\n",
      " [0.   0.66 0.  ]]\n",
      "------------------\n",
      "E 0 B 1066 loss: 24.623416900634766\n",
      "[[0.09 0.09 0.  ]\n",
      " [0.12 0.17 0.13]\n",
      " [0.12 0.11 0.17]]\n",
      "[[0.06 0.07 0.01]\n",
      " [0.12 0.17 0.12]\n",
      " [0.13 0.11 0.21]]\n",
      "------------------\n",
      "E 1 B 0 loss: 42.327117919921875\n",
      "[[0.12 0.12 0.  ]\n",
      " [0.12 0.18 0.24]\n",
      " [0.   0.   0.24]]\n",
      "[[0.12 0.09 0.01]\n",
      " [0.11 0.13 0.26]\n",
      " [0.   0.   0.28]]\n",
      "------------------\n",
      "E 1 B 533 loss: 44.025203704833984\n",
      "[[0.13 0.12 0.  ]\n",
      " [0.14 0.19 0.13]\n",
      " [0.15 0.14 0.  ]]\n",
      "[[0.13 0.11 0.01]\n",
      " [0.17 0.18 0.13]\n",
      " [0.15 0.13 0.  ]]\n",
      "------------------\n",
      "E 1 B 1066 loss: 30.499832153320312\n",
      "[[0.14 0.11 0.09]\n",
      " [0.15 0.19 0.  ]\n",
      " [0.17 0.15 0.  ]]\n",
      "[[0.13 0.11 0.12]\n",
      " [0.13 0.21 0.  ]\n",
      " [0.16 0.12 0.  ]]\n",
      "------------------\n",
      "E 2 B 0 loss: 44.56074142456055\n",
      "[[0.16 0.14 0.19]\n",
      " [0.16 0.22 0.  ]\n",
      " [0.   0.14 0.  ]]\n",
      "[[0.17 0.13 0.14]\n",
      " [0.16 0.26 0.  ]\n",
      " [0.   0.13 0.  ]]\n",
      "------------------\n",
      "E 2 B 533 loss: 39.99378967285156\n",
      "[[0.1  0.1  0.1 ]\n",
      " [0.11 0.18 0.  ]\n",
      " [0.14 0.11 0.15]]\n",
      "[[0.1  0.11 0.12]\n",
      " [0.13 0.15 0.  ]\n",
      " [0.14 0.1  0.15]]\n",
      "------------------\n",
      "E 2 B 1066 loss: 32.36885070800781\n",
      "playing gen: 1\n",
      "100%|███████████████| 10000/10000 [0:00:00 |  0.0159_itr]\n",
      "generating data\n",
      "100%|███████████████| 10000/10000 [0:00:00 |  0.0128_itr]\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0.06 0.06 0.08]\n",
      " [0.14 0.07 0.11]\n",
      " [0.22 0.2  0.07]]\n",
      "------------------\n",
      "E 0 B 0 loss: 72.65560913085938\n",
      "[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0.03 0.02 0.01]\n",
      " [0.59 0.02 0.01]\n",
      " [0.   0.11 0.22]]\n",
      "------------------\n",
      "E 0 B 540 loss: 40.79829025268555\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "[[0.   0.   0.  ]\n",
      " [0.   0.   0.99]\n",
      " [0.01 0.   0.  ]]\n",
      "------------------\n",
      "E 0 B 1080 loss: 5.370464324951172\n",
      "[[0.   0.   0.  ]\n",
      " [0.06 0.   0.12]\n",
      " [0.   0.   0.81]]\n",
      "[[0.   0.   0.01]\n",
      " [0.02 0.   0.1 ]\n",
      " [0.01 0.   0.85]]\n",
      "------------------\n",
      "E 1 B 0 loss: 30.715476989746094\n",
      "[[0.07 0.1  0.14]\n",
      " [0.13 0.3  0.  ]\n",
      " [0.16 0.11 0.  ]]\n",
      "[[0.08 0.14 0.1 ]\n",
      " [0.15 0.21 0.01]\n",
      " [0.22 0.09 0.  ]]\n",
      "------------------\n",
      "E 1 B 540 loss: 31.62021255493164\n",
      "[[0.11 0.09 0.17]\n",
      " [0.11 0.28 0.1 ]\n",
      " [0.12 0.   0.  ]]\n",
      "[[0.1  0.1  0.16]\n",
      " [0.1  0.27 0.12]\n",
      " [0.12 0.02 0.01]]\n",
      "------------------\n",
      "E 1 B 1080 loss: 4.0862627029418945\n",
      "[[0.   0.   0.03]\n",
      " [0.29 0.   0.42]\n",
      " [0.19 0.06 0.  ]]\n",
      "[[0.   0.01 0.04]\n",
      " [0.18 0.   0.48]\n",
      " [0.23 0.07 0.  ]]\n",
      "------------------\n",
      "E 2 B 0 loss: 34.5241813659668\n",
      "[[0.   0.11 0.14]\n",
      " [0.11 0.19 0.09]\n",
      " [0.14 0.08 0.15]]\n",
      "[[0.   0.13 0.14]\n",
      " [0.09 0.17 0.09]\n",
      " [0.13 0.08 0.16]]\n",
      "------------------\n",
      "E 2 B 540 loss: 37.581809997558594\n",
      "[[0.1  0.1  0.14]\n",
      " [0.13 0.   0.18]\n",
      " [0.13 0.1  0.12]]\n",
      "[[0.09 0.06 0.16]\n",
      " [0.17 0.   0.18]\n",
      " [0.09 0.1  0.15]]\n",
      "------------------\n",
      "E 2 B 1080 loss: 7.853403091430664\n",
      "playing gen: 2\n",
      "100%|███████████████| 10000/10000 [0:00:00 |  0.0135_itr]\n",
      "generating data\n",
      "100%|███████████████| 10000/10000 [0:00:00 |  0.0112_itr]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "[[0.06 0.15 0.07]\n",
      " [0.18 0.06 0.14]\n",
      " [0.07 0.15 0.11]]\n",
      "------------------\n",
      "E 0 B 0 loss: 73.71267700195312\n",
      "[[0.   0.03 0.94]\n",
      " [0.03 0.   0.  ]\n",
      " [0.   0.   0.  ]]\n",
      "[[0.01 0.05 0.88]\n",
      " [0.02 0.   0.01]\n",
      " [0.   0.01 0.01]]\n",
      "------------------\n",
      "E 0 B 536 loss: 33.67341995239258\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0.99 0.   0.  ]\n",
      " [0.   0.   0.  ]\n",
      " [0.   0.   0.  ]]\n",
      "------------------\n",
      "E 0 B 1072 loss: 20.932899475097656\n",
      "[[0.08 0.05 0.  ]\n",
      " [0.07 0.19 0.09]\n",
      " [0.08 0.   0.43]]\n",
      "[[0.05 0.03 0.  ]\n",
      " [0.06 0.17 0.1 ]\n",
      " [0.07 0.   0.5 ]]\n",
      "------------------\n",
      "E 1 B 0 loss: 35.012290954589844\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "[[0.01 0.   0.  ]\n",
      " [0.   0.   0.02]\n",
      " [0.96 0.   0.  ]]\n",
      "------------------\n",
      "E 1 B 536 loss: 26.94663429260254\n",
      "[[0.03 0.03 0.25]\n",
      " [0.   0.   0.  ]\n",
      " [0.   0.   0.69]]\n",
      "[[0.04 0.03 0.13]\n",
      " [0.02 0.   0.  ]\n",
      " [0.   0.01 0.76]]\n",
      "------------------\n",
      "E 1 B 1072 loss: 20.760726928710938\n",
      "[[0.11 0.1  0.13]\n",
      " [0.08 0.   0.14]\n",
      " [0.14 0.09 0.2 ]]\n",
      "[[0.11 0.15 0.16]\n",
      " [0.07 0.   0.12]\n",
      " [0.12 0.09 0.18]]\n",
      "------------------\n",
      "E 2 B 0 loss: 31.471696853637695\n",
      "[[0.08 0.   0.18]\n",
      " [0.2  0.   0.04]\n",
      " [0.35 0.   0.16]]\n",
      "[[0.12 0.01 0.32]\n",
      " [0.21 0.   0.05]\n",
      " [0.11 0.   0.18]]\n",
      "------------------\n",
      "E 2 B 536 loss: 35.087005615234375\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "------------------\n",
      "E 2 B 1072 loss: 26.49127769470215\n"
     ]
    }
   ],
   "source": [
    "from prgs import prgs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "import mcst\n",
    "from mcst import S, model, State\n",
    "from importlib import reload\n",
    "import f; reload(f)\n",
    "from f import f_gm\n",
    "import ftemp; reload(ftemp)\n",
    "from ftemp import ftemp\n",
    "\n",
    "K = 3\n",
    "# TODO: \n",
    "# 1. Data aug\n",
    "# 2. More eff forward and backward\n",
    "#   * big bottleneck is f_gm on gpu\n",
    "#   * second bottleneck is cpu\n",
    "# 3. Evaluation compare of fa and fb\n",
    "# \n",
    "# 2&3 related\n",
    "#\n",
    "# Half Prec Train?? (Later)\n",
    "\n",
    "def ploss(p, pi): \n",
    "    ''' Given input of p, pi of (b,K*K) will compute the batched loss\n",
    "    '''\n",
    "    loss = - torch.bmm( pi.unsqueeze(1), torch.log(p.unsqueeze(2))  )\n",
    "    #loss = -torch.log( -torch.abs(pi-p)+1 )\n",
    "    return loss.sum()\n",
    "\n",
    "mcst.model = ftemp(K).cuda()\n",
    "for GEN in range(3):\n",
    "    \n",
    "    S = State(K)\n",
    "    print('playing gen:', GEN)\n",
    "    if GEN==0:\n",
    "        G = SVG\n",
    "    else:\n",
    "        for i in prgs( range(10000) ): ply()\n",
    "        print('generating data')\n",
    "        G = []\n",
    "        for i in prgs( range(10000) ): G+=ply(4)\n",
    "                \n",
    "    GNZ = []\n",
    "    for g in G:\n",
    "        x,y,z = g\n",
    "        if x[0].sum() != 0:\n",
    "            GNZ.append(g)\n",
    "    trn_dataloader = DataLoader(GNZ, batch_size=32, shuffle=True)\n",
    "    \n",
    "    E,B = 3, len(trn_dataloader)\n",
    "    \n",
    "    mcst.model = ftemp(K).cuda()\n",
    "    optimizer = Adam( mcst.model.parameters(), lr=.002, betas=(0.5,0.999), eps=1e-04, weight_decay=1e-5)    \n",
    "    mcst.model.train()\n",
    "    for e in range(E):\n",
    "        for b, batch in enumerate(trn_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x,pi,z = batch\n",
    "            x = x.float().cuda()\n",
    "            pi = pi.cuda()\n",
    "            z = z.unsqueeze(1).float().cuda();z[z ==-1] = .5\n",
    "            \n",
    "            p,v = mcst.model(x)\n",
    "            lA, lB =  ((v-z)**2).sum() , ploss(p,pi) \n",
    "            l = lA + lB\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            if b%(B//2)==0: \n",
    "                print( pi[0].reshape(3,3).cpu().detach().numpy().round(2) )\n",
    "                print( p[0].reshape(3,3).cpu().detach().numpy().round(2) )\n",
    "                print('------------------')\n",
    "                \n",
    "            if b%(B//2)==0: \n",
    "                print('E',e,'B',b,'loss:',lA.item(), lB.item())\n",
    "                #print('E',e,'B',b,'loss:',l.item() )\n",
    "                \n",
    "    mcst.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False],\n",
       "         [False, False, False],\n",
       "         [ True, False,  True]],\n",
       "\n",
       "        [[False,  True, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z = g\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 2 2]\n",
      " [1 0 1]]\n",
      "player  1\n",
      "[[ 0.   0.   0. ]\n",
      " [42.1  0.   0. ]\n",
      " [ 0.  57.9  0. ]]\n"
     ]
    }
   ],
   "source": [
    "g = GNZ[1730]\n",
    "util.visualize( g )\n",
    "x,y,z = g \n",
    "#M = torch.IntTensor(M)\n",
    "#p1,p2 = (M==1), (M==2)                                                                                                                                                                                   \n",
    "#plyr = 1\n",
    "#p = torch.full(p1.shape, plyr).bool()                                                                                                                                                                    \n",
    "x = x.float().cuda().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.  ]\n",
      " [89.54  0.    0.  ]\n",
      " [ 0.    9.73  0.  ]] tensor([[-0.3351]], device='cuda:0', grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "mcst.model.eval()\n",
    "p,z = mcst.model(x)\n",
    "p[p*100 < 2] = 0\n",
    "print( (p.reshape(3,3).cpu().detach().numpy()*100).round(2), z )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12 0.1  0.14]\n",
      " [0.09 0.09 0.11]\n",
      " [0.13 0.11 0.11]] tensor([[-0.0614]], device='cuda:0', grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "mcst.model.eval()\n",
    "p,z = mcst.model(x)\n",
    "print( p.reshape(3,3).cpu().detach().numpy().round(2), z )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "##= mcst.F(0)\n",
    "#np.random.choice(len(dist)), dist\n",
    "\n",
    "##################################################################\n",
    "# FUTURE #########################################################\n",
    "##################################################################\n",
    "# Multiprocess of S and F\n",
    "\n",
    "def F(S,rank,world):    \n",
    "    # load S->x into global (ready)\n",
    "    # wait loop if all ready: (rank 0 will start _F)\n",
    "    # wait for _F result\n",
    "    # retrieve\n",
    "    # return\n",
    "    \n",
    "def _F():\n",
    "    # take global [x,x,x]\n",
    "    # batch stack\n",
    "    # run _F (Keep instance of f_gm alive on cuda)\n",
    "    # split results and load _F result on global\n",
    "    \n",
    "S = [State, State, State] #rank/world\n",
    "\n",
    "# How to prevent diff nodes calling F?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
